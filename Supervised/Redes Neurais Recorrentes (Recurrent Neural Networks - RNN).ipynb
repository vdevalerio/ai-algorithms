{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b3751d",
   "metadata": {},
   "source": [
    "# Redes Neurais Recorrentes (Recurrent Neural Networks - RNN)\n",
    "# Redes Neurais Recorrentes (RNN) são um tipo de rede neural especialmente adequada para processar sequências de dados, como séries temporais, texto, áudio ou qualquer outra forma de dados onde a ordem temporal é relevante. A característica principal das RNNs é a capacidade de usar informações de entradas anteriores para influenciar o processamento atual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb092f",
   "metadata": {},
   "source": [
    "## Como funciona\n",
    "* Loop Temporal: Ao contrário das redes neurais tradicionais, as RNNs possuem um loop que permite que a informação persista, ou seja, as saídas de um passo são usadas como entradas para o próximo passo.\n",
    "* Processamento Sequencial: Em cada etapa temporal, a RNN processa um elemento da sequência de entrada, atualiza seu estado (memória) com base nesse elemento e o estado anterior, e produz uma saída.\n",
    "* Estado Oculto: O estado oculto (memória) da RNN tenta capturar e armazenar informações sobre as entradas que a rede já processou, o que é crucial para tarefas onde o contexto histórico é importante.\n",
    "* Backpropagation Through Time (BPTT): Para treinar uma RNN, utiliza-se uma variante do backpropagation chamada BPTT, onde os gradientes são propagados para trás através de cada passo da sequência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7712dbb",
   "metadata": {},
   "source": [
    "### Vantagens\n",
    "* Adequação para Dados Sequenciais: As RNNs são naturalmente adequadas para dados sequenciais e podem lidar com entradas de comprimento variável.\n",
    "* Modelagem de Dependências Temporais: Podem modelar dependências temporais de diferentes comprimentos, o que é crucial em muitas aplicações práticas, como na linguagem natural.\n",
    "* Uso Compartilhado de Parâmetros: Ao contrário das redes densas, as RNNs compartilham os mesmos parâmetros em todos os passos de tempo, o que as torna mais eficientes e menos propensas a sobreajustar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbfa3ad",
   "metadata": {},
   "source": [
    "### Desvantagens\n",
    "* Problema do Desaparecimento do Gradiente: As RNNs tradicionais têm dificuldade em capturar dependências de longo prazo devido ao desaparecimento do gradiente durante o treinamento.\n",
    "* Desafios Computacionais: O treinamento de RNNs pode ser computacionalmente desafiador e demorado, especialmente para sequências longas.\n",
    "* Dificuldade em Paralelização: Diferentemente das CNNs, o processamento sequencial das RNNs dificulta a paralelização, tornando o treinamento mais lento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838dcbce",
   "metadata": {},
   "source": [
    "#### Exemplo de código com RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "974be881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:15:14.725171: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aff9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60115a25",
   "metadata": {},
   "source": [
    "#### Construção do modelo RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5912d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 15:15:42.857002: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0f1857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 726s 5s/step - loss: 0.6064 - acc: 0.6633 - val_loss: 0.8498 - val_acc: 0.5304\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 922s 6s/step - loss: 0.3937 - acc: 0.8367 - val_loss: 0.3999 - val_acc: 0.8260\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 878s 6s/step - loss: 0.3126 - acc: 0.8748 - val_loss: 0.4335 - val_acc: 0.7984\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 748s 5s/step - loss: 0.2553 - acc: 0.9016 - val_loss: 0.3931 - val_acc: 0.8104\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 848s 5s/step - loss: 0.2136 - acc: 0.9194 - val_loss: 0.3607 - val_acc: 0.8598\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 784s 5s/step - loss: 0.1595 - acc: 0.9420 - val_loss: 0.4189 - val_acc: 0.8186\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 862s 6s/step - loss: 0.1166 - acc: 0.9597 - val_loss: 0.4720 - val_acc: 0.8460\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 836s 5s/step - loss: 0.0866 - acc: 0.9730 - val_loss: 0.4442 - val_acc: 0.8534\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 656s 4s/step - loss: 0.0637 - acc: 0.9801 - val_loss: 0.5044 - val_acc: 0.8322\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 659s 4s/step - loss: 0.0497 - acc: 0.9849 - val_loss: 0.5269 - val_acc: 0.8384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f31e376d210>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "746669e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 106s 135ms/step - loss: 0.1320 - mae: 0.1788\n",
      "Test Accuracy: 17.88\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test Accuracy: %.2f' % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d4c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
